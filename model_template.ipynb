{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\n",
    "    '<START>', '<END>', '<PAD>', 'measure', 'note', 'pitch', 'step', 'alter',\n",
    "    'octave', 'duration', 'type', 'rest', 'dot', 'staff', 'notations', 'slur',\n",
    "    'ff', 'f', 'mf', 'mp', 'p', 'pp', 'backup', 'chord'] + list('ABCDEFG') + ['-1'] + list('0123456789') + ['10', '11', '12', '13', '14', '15', '16']\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(tokens)}\n",
    "ix_to_word = {str(i): word for i, word in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'storage/datasets/'\n",
    "lstm_hidden_size = 256\n",
    "fc1_output_size = 256\n",
    "seq_len = 64\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_signature_layer(measure_length, height=224, width=224):\n",
    "    # measure length is 0 for 4/4 and 1 for 3/4\n",
    "    x = np.zeros((height, width)).astype(np.uint8)\n",
    "    if measure_length == 12:\n",
    "        x[:int(height/2)] += 255\n",
    "    if measure_length == 16:\n",
    "        x[int(height/2):] += 255\n",
    "    return x\n",
    "\n",
    "def get_key_signature_layer(key_number, height=224, width=224):\n",
    "    # key number is between -7 and 7 inclusive\n",
    "    x = np.zeros((height, width)).astype(np.uint8)\n",
    "    splits = np.array_split(x, 15)\n",
    "    splits[key_number+7] += 255\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, path, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "        self.images = np.load(path + 'images.npy')\n",
    "        self.measure_lengths = np.load(path + 'measure_lengths.npy')\n",
    "        self.key_numbers = np.load(path + 'key_numbers.npy')\n",
    "        with open(path + 'pc_data.json') as f:\n",
    "            self.pc_data = json.load(f)\n",
    "        self.pc_data_encoded = []\n",
    "        self.sequences = []\n",
    "        self.image_indices = []\n",
    "        for i, pc in enumerate(pc_data):\n",
    "            if len(pc) < seq_len+1:\n",
    "                pc = pc + ['<PAD>']*(seq_len+1-len(pc))\n",
    "            pc_as_ix = np.array([int(word_to_ix[word]) for word in pc])\n",
    "            for j in range(len(pc)-seq_len):\n",
    "                self.sequences.append(pc_as_ix[j:j+seq_len+1])\n",
    "                self.image_indices.append(i)\n",
    "        self.image_indices = np.array(self.image_indices)\n",
    "            \n",
    "    def get_batch(self, batch_size, val=False):\n",
    "        validation_partition = int(len(self.sequences)*0.9)\n",
    "        if not val:\n",
    "            sequence_batch_indices = np.random.choice(len(self.sequences[:validation_partition]), size=batch_size)\n",
    "        else:\n",
    "            sequence_batch_indices = np.random.choice(len(self.sequences[validation_partition:]), size=batch_size)\n",
    "        image_batch_indices = self.image_indices[sequence_batch_indices]\n",
    "        raw_image_batch = images[image_batch_indices].reshape(-1, 1, 224, 224)\n",
    "        measure_lengths_batch = self.measure_lengths[image_batch_indices]\n",
    "        key_numbers_batch = self.key_numbers[image_batch_indices]\n",
    "        measure_lengths_layers = []\n",
    "        key_numbers_layers = []\n",
    "        for i in range(batch_size):\n",
    "            measure_length = measure_lengths_batch[i]\n",
    "            key_numbers_batch = measure_lengths_batch[i]\n",
    "            measure_lengths_layers.append(get_time_signature_layer(measure_length))\n",
    "            key_numbers_layers.append(get_key_signature_layer(key_numbers))\n",
    "        measure_lengths_layers = np.array(measure_lengths_layers).reshape(-1, 1, 224, 224)\n",
    "        key_numbers_layers = np.array(key_numbers_layers).reshape(-1, 1, 224, 224)\n",
    "        image_batch = np.array([raw_image_batch, measure_lengths_layers, key_numbers_layers], axis=1)\n",
    "        sequence_batch = self.sequences[sequence_batch_indices]\n",
    "        image_batch = torch.Tensor(image_batch).type(torch.float).to(device)\n",
    "        sequence_batch = torch.Tensor(sequence_batch).type(torch.float).to(device)\n",
    "        return image_batch, sequence_batch, image_batch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(n):\n",
    "    all_datasets = os.listdir(dataset_dir)\n",
    "    dataset_sample = []\n",
    "    for _ in range(n):\n",
    "        i = np.random.randint(len(all_datasets))\n",
    "        filename = all_datasets[i]\n",
    "        dataset = Dataset(dataset_dir + filename, seq_len)\n",
    "        dataset_sample.append(dataset)\n",
    "    return dataset_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSubunit(nn.Module):\n",
    "    def __init__(self, input_size, output_size, filter_size, stride, padding, dropout):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_size, output_size, filter_size, stride=stride, padding=padding)\n",
    "        self.dp = nn.Dropout2d(p=dropout)\n",
    "        self.bn = nn.BatchNorm2d(output_size)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sequential = nn.Sequential(self.conv, self.dp, self.bn, self.relu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "    \n",
    "class LargeConvUnit(nn.Module):\n",
    "    def __init__(self, input_size, output_size, filter_size, stride, padding, dropout):\n",
    "        super().__init__()\n",
    "        self.subunit1 = ConvSubunit(input_size, output_size, filter_size, 1, padding, dropout)\n",
    "        self.subunit2 = ConvSubunit(output_size, output_size, filter_size, 1, padding, dropout)\n",
    "        self.subunit3 = ConvSubunit(output_size, output_size, filter_size, 1, padding, dropout)\n",
    "        self.subunit4 = ConvSubunit(output_size, output_size, filter_size, stride, padding, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.subunit1(x)\n",
    "        cache = x\n",
    "        x = self.subunit2(x)\n",
    "        x = self.subunit3(x)\n",
    "        x = x + cache\n",
    "        x = self.subunit4(x)\n",
    "        return x\n",
    "    \n",
    "class SmallConvUnit(nn.Module):\n",
    "    def __init__(self, input_size, output_size, filter_size, stride, padding, dropout):\n",
    "        super().__init__()\n",
    "        self.subunit1 = ConvSubunit(input_size, output_size, filter_size, 1, padding, dropout)\n",
    "        self.subunit2 = ConvSubunit(output_size, output_size, filter_size, stride, padding, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.subunit1(x)\n",
    "        x = self.subunit2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(SmallConvUnit(3, 32, 3, 2, 1, 0.1), # (224, 224) --> (112, 112)\n",
    "                                 SmallConvUnit(32, 64, 3, 2, 1, 0.1), # (112, 112) --> (56, 56)\n",
    "                                 SmallConvUnit(64, 128, 3, 4, 1, 0.1), # (56, 56) --> (14, 14)\n",
    "                                 SmallConvUnit(128, 256, 3, 7, 1, 0.1)) # (14, 14) --> (2, 2)\n",
    "        self.fc = nn.Linear(1024, fc_output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        \n",
    "class LargeCNN(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(LargeConvUnit(3, 32, 3, 2, 1, 0.1), # (224, 224) --> (112, 112)\n",
    "                                 LargeConvUnit(32, 64, 3, 2, 1, 0.1), # (112, 112) --> (56, 56)\n",
    "                                 LargeConvUnit(64, 128, 3, 4, 1, 0.1), # (56, 56) --> (14, 14)\n",
    "                                 LargeConvUnit(128, 256, 3, 7, 1, 0.1)) # (14, 14) --> (2, 2)\n",
    "        self.fc = nn.Linear(1024, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "class SqueezeCNN(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.cnn = torchvision.models.squeezenet1_0(pretrained=True)\n",
    "        self.cnn.classifier[1] = nn.Conv2d(512, output_size, kernel_size=(1,1), stride=(1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, save_dir, cnn, len_lexicon, lstm_hidden_size, fc1_output_size, num_directions=2 device):\n",
    "        super().__init__()\n",
    "        self.save_dir = save_dir\n",
    "        self.len_lexicon = len_lexicon\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.fc1_output_size = fc1_output_size\n",
    "        self.num_directions = num_directions\n",
    "        self.bidirectional = (num_directions==2)\n",
    "        self.cnn = cnn\n",
    "        self.embed = nn.Embedding(num_embeddings=self.len_lexicon, embedding_dim=5)\n",
    "        self.lstm1 = nn.LSTM(input_size=5,\n",
    "                             hidden_size=self.lstm_hidden_size,\n",
    "                             num_layers=2,\n",
    "                             batch_first=True,\n",
    "                             dropout=0.3,\n",
    "                             bidirectional=self.bidirectional)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.fc1_output_size+self.lstm_hidden_size,\n",
    "                             hidden_size=self.lstm_hidden_size,\n",
    "                             num_layers=2,\n",
    "                             batch_first=True,\n",
    "                             dropout=0.3,\n",
    "                             bidirectional=self.bidirectional)\n",
    "        self.fc2 = nn.Linear(self.lstm_hidden_size, self.len_lexicon)\n",
    "        \n",
    "    def forward(self, image_input, sequence_input, internal1=None, internal2=None):\n",
    "        bs = image_input.shape[0]\n",
    "        sl = language_input.shape[1]\n",
    "        if internal1:\n",
    "            h1, c1 = internal1\n",
    "        else:\n",
    "            h1 = torch.zeros(2*self.num_directions, bs, self.lstm_hidden_size).to(device)\n",
    "            c1 = torch.zeros(2*self.num_directions, bs, self.lstm_hidden_size).to(device)\n",
    "        if internal2:\n",
    "            h2, c2 = internal2\n",
    "        else:\n",
    "            h2 = torch.zeros(2*self.num_directions, bs, self.lstm_hidden_size).to(device)\n",
    "            c2 = torch.zeros(2*self.num_directions, bs, self.lstm_hidden_size).to(device)\n",
    "        image_output = self.cnn(image_input)\n",
    "        image_output = image_output.repeat(1, sl).view(bs, sl, self.fc1_output_size)\n",
    "        sequence_output, (h1, c1) = self.lstm1(self.embed(sequence_input), (h1, c1))\n",
    "        concatenated = torch.cat([image_output, sequence_output], 2)\n",
    "        lstm2_out, (h2, c2) = self.lstm2(concatenated, (h2, c2))\n",
    "        out = self.fc2(lstm2_out)\n",
    "        return out, (h1, c1), (h2, c2)\n",
    "    \n",
    "    def fit(self, datasets, iterations, batch_size, optimizer, loss_fn, print_every=100, save_every=5000, train_time=0, past_iterations=0):\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "        time_checkpoint = time.time()\n",
    "        dataset_index = -1\n",
    "        for i in range(iterations):\n",
    "            if i % 1000 == 0:\n",
    "                dataset_index = (dataset_index+1) % len(datasets)\n",
    "            dataset = datasets[dataset_index]\n",
    "            arr, seq, _ = dataset.get_batch(batch_size)\n",
    "            seq1 = seq[:, :-1]\n",
    "            seq2 = seq[:, 1:]\n",
    "            out, _, _ = self.forward(arr, seq1)\n",
    "            out = out.view(-1, self.len_lexicon)\n",
    "            targets = seq2.view(-1)\n",
    "            loss = loss_fn(out, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_time += time.time() - time_checkpoint\n",
    "            time_checkpoint = time.time()\n",
    "            if i % print_every == 0:\n",
    "                arr, _, image_batch_indices = dataset.get_batch(1, val=True)\n",
    "                pc = dataset.pc_data[image_batch_indices[0]]\n",
    "                pc = ' '.join([ix_to_word[str(ix)] for ix in pc])\n",
    "                pred_seq = self.predict(arr)\n",
    "                pred_seq = ' '.join(pred_seq)\n",
    "                pred_seq2 = self.predict_stochastic(arr)\n",
    "                pred_seq2 = ' '.join(pred_seq2)\n",
    "                with open(f'{save_dir}log.txt', 'a+') as f:\n",
    "                    info_string = f\"\"\"\n",
    "                    ----\n",
    "                    iteration: {i}\n",
    "                    time elapsed: {train_time}\n",
    "                    loss: {loss}\n",
    "                    ----\n",
    "                    pred1: {pred_seq}\n",
    "                    ----\n",
    "                    pred2: {pred_seq2}\n",
    "                    ----\n",
    "                    true:  {pc}\n",
    "                    ----\n",
    "\n",
    "\n",
    "\n",
    "                    \"\"\".replace('    ', '')\n",
    "                    print(info_string)\n",
    "                    f.write(info_string)\n",
    "            if i % save_every == 0 and i != 0:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] *= 0.92\n",
    "                torch.save(self.state_dict(), f'{self.save_dir}checkpoint_iteration_{past_iterations+i}.pt')\n",
    "                with open(f'{self.save_dir}training_info.json', 'w+') as f:\n",
    "                    json.dump({'train_time': train_time, 'past_iterations': past_iterations+i}, f)\n",
    "                    \n",
    "    def resume_fit(self, iterations, optimizer, loss_fn, print_every=100, save_every=5000):\n",
    "        with open(f'{self.save_dir}training_info.json', 'w+') as f:\n",
    "            training_info = json.load(f)\n",
    "        train_time = training_info['train_time']\n",
    "        past_iterations = training_info['past_iterations']\n",
    "        checkpoint = torch.load(f'{self.save_dir}checkpoint_iteration_{past_iterations}.pt')\n",
    "        self.load_state_dict(checkpoint)\n",
    "        self.fit(iterations, optimizer, loss_fn, print_every=print_every, save_every=save_every, train_time=train_time, past_iterations=past_iterations)\n",
    "                \n",
    "             \n",
    "    def predict(self, arr):\n",
    "        self.eval()    \n",
    "        with torch.no_grad():\n",
    "            arr = arr.view(1,3, 224, 224)\n",
    "            output_sequence = ['<START>']\n",
    "            h1 = torch.zeros(2*self.num_directions, 1, self.lstm_hidden_size).to(device)\n",
    "            c1 = torch.zeros(2*self.num_directions, 1, self.lstm_hidden_size).to(device)\n",
    "            h2 = torch.zeros(2*self.num_directions, 1, self.lstm_hidden_size).to(device)\n",
    "            c2 = torch.zeros(2*self.num_directions, 1, self.lstm_hidden_size).to(device)\n",
    "            while output_sequence[-1] != '<END>' and len(output_sequence)<400:\n",
    "                language_input = torch.Tensor([word_to_ix[output_sequence[-1]]]).type(torch.long).view(1, 1).to(device)\n",
    "                out, (h1, c1), (h2, c2) = self.forward(arr, language_input, (h1, c1), (h2, c2))\n",
    "                _, language_input = out[0, 0, :].max(0)\n",
    "                output_sequence.append(ix_to_word[str(language_input.item())])\n",
    "        self.train()\n",
    "        return output_sequence\n",
    "    \n",
    "    def predict_stochastic(self, arr):\n",
    "        self.eval()    \n",
    "        with torch.no_grad():\n",
    "            arr = arr.view(1,3, 224, 224)\n",
    "            output_sequence = ['<START>']\n",
    "            h1 = torch.zeros(2*self.num_directions, 1, self.lstm_hidden_size).to(device)\n",
    "            c1 = torch.zeros(2*self.num_directions, 1, self.lstm_hidden_size).to(device)\n",
    "            h2 = torch.zeros(2*self.num_directions, 1, self.lstm_hidden_size).to(device)\n",
    "            c2 = torch.zeros(2*self.num_directions, 1, self.lstm_hidden_size).to(device)\n",
    "            while output_sequence[-1] != '<END>' and len(output_sequence)<400:\n",
    "                language_input = torch.Tensor([word_to_ix[output_sequence[-1]]]).type(torch.long).view(1, 1).to(device)\n",
    "                out, (h1, c1), (h2, c2) = self.forward(arr, language_input, (h1, c1), (h2, c2))\n",
    "                log_probs = out[0, 0, :].cpu().numpy()\n",
    "                probs = np.exp(log_probs) / np.exp(log_probs).sum()\n",
    "                predicted_ix = np.random.choice(len_lexicon, p=probs)\n",
    "                output_sequence.append(ix_to_word[str(predicted_ix)])\n",
    "        self.train()\n",
    "        return output_sequence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
